---
title: "presentation2"
output: html_document
---

For my final project I wanted to explore college basketball and what leads to Mid-Major programs pulling off upsets. First things first I need to load various libraries that I'll use.


```{r}
library(tidyverse)
library(ggrepel)
library(lubridate)
library(purrr)
library(tidyr)
```

My initial hope was to explore tournament upsets since those are the most dramatic and what make people fall in love with college basketball. This data proved more difficult then I expected to obtain, so I pivoted to using full game log data and looking at any games where non-power conference teams beat power-conference teams (more on the distinction in a minute). Although, not as many people are likely interested in Dayton beating Florida State in December as they are in UMBC beating Virginia in March, looking at the full year of data should give me a more extensive dataset and help me find more statistically significant overall trends.

```{r}
logs <- read_csv("https://thescoop.org/sports-data-files/cbblogs1526.csv")
```

Then came delegating teams into their respective areas, which is more tricky then I'd like it to be. For starters I delegated the obvious power conferences: ACC, Big Ten, Big 12, SEC, Pac-12(RIP/welcome back?), and the Big East. Since my data spans back to the 2014-15 season though, there are a lot of schools that moved in or out of power conferences during the realignment process so I decided to delegate those as power as well. Then obviously as any fans of the blog https://www.midmajormadness.com/ know: Gonzaga is not a mid-major.

```{r}

power6 <- c(
  "ACC", "ACC MBB", "Big Ten", "Big Ten MBB", "Big 12", "Big 12 MBB", "SEC", "SEC MBB", "Pac-12", "Pac-12 MBB", "Big East", "Big East MBB", "Gonzaga"
)

extra_power <- c(
"Brigham Young",  "Central Florida", "Cincinnati", "Connecticut", 
  "Houston", "Memphis", "Oregon State", 
  "Southern Methodist", "UCF", "Washington State"
)


logs <- logs |>  
  mutate(
    Classification = if_else(
      Conference %in% power6 | Team %in% extra_power,
      "Power",
      "Mid-Major"
    )
  )
```

From here I set up a data frame to find all the victories for midmajors over power conferences in the years my data spans. 
```{r}
classifications <- logs |> 
  group_by(Team) |> 
  summarize(Classification = first(Classification), .groups = "drop")

logs <- logs |> mutate(Margin = TeamScore - OpponentScore)

logs <- logs |> 
  select(-matches("Classification_team|Classification_opp")) |> 
  left_join(classifications, by = "Team", suffix = c("", "_team")) |> 
  left_join(classifications, by = c("Opponent" = "Team"), suffix = c("", "_opp"))


upsets <- logs |> 
  filter(Classification_team == "Mid-Major",
         Classification_opp == "Power",
         W_L == "W")

upsets <- upsets |> 
  distinct(Team, Opponent, Date, .keep_all = TRUE)
```

```{r}
upsets <- upsets |> 
  dplyr::select(Team, everything())

upsets <- upsets |> 
  filter(Team != "Gonzaga")
```

From here I had to modify some of my data as I prepared to create a predictive model for winning college basketball games.


```{r}
winlosslogs <- logs |> 
  mutate(winloss = case_when(
    grepl("W", W_L) ~ 1, 
    grepl("L", W_L) ~ 0)
) 

winlosslogs <- winlosslogs |> 
  mutate(
    ToMargin = TeamTurnovers - OpponentTurnovers,
    threepointdiscrepancy = Team3PPCT - Opponent3PPCT,
    FTmargin = TeamFTA - OpponentFTA
  )

winlosslogs <- winlosslogs |>
  filter(!is.na(ToMargin) & !is.na(threepointdiscrepancy) & !is.na(TeamFTA))

modelwinlosslogs <- winlosslogs |> mutate(Season = str_extract(Season, "\\d{4}$")) |> 
  filter(Season < 2025 )

```

Then I made my model, focusing on turnover margin, the margin in three point percentage, and then margin in free throws attempted. These are three factors I believe to be highly important in college game and my model and it's output supported that. 

```{r}
model <- glm(
  winloss ~ ToMargin + threepointdiscrepancy + FTmargin, 
  data = modelwinlosslogs, 
  family = binomial
)

summary(model)

```
I then modified my logs to include some of the predictions my model made.

```{r}
modelwinlosslogs <- modelwinlosslogs |> mutate(predicted_prob = predict(model, type="response"))

modelwinlosslogs <- modelwinlosslogs |> mutate(predicted_outcome = ifelse(modelwinlosslogs$predicted_prob > 0.5, 1, 0))

table(Actual = modelwinlosslogs$winloss, 
      Predicted = modelwinlosslogs$predicted_outcome)

mean(modelwinlosslogs$predicted_outcome == modelwinlosslogs$winloss, na.rm = TRUE)
```

```{r}

modelwinlosslogs <- modelwinlosslogs |> 
  dplyr::select(Team, everything())

modelwinlosslogs |> filter(winloss == "1") |> 
arrange(predicted_prob) |> 
select(Team, Date, Opponent, TeamScore, OpponentScore, ToMargin, threepointdiscrepancy,FTmargin, predicted_prob)
```

I used the statistics to create my model based on the season from 2014-15 to 2023-24 in order to be able to use it to make predictions for last season and this current one. I returned to upsets data frame to have the model predict wins or losses in all the upset games based on my chosen statistics.

```{r}



upsets <- upsets |> mutate(
   ToMargin = TeamTurnovers - OpponentTurnovers,
    threepointdiscrepancy = Team3PPCT - Opponent3PPCT,
    FTmargin = TeamFTA - OpponentFTA
)

upsets <- upsets |> 
  mutate(winloss = case_when(
    grepl("W", W_L) ~ 1, 
    grepl("L", W_L) ~ 0)
) 

pred_probs <- predict(
  model, 
  newdata = upsets,
  type = "response"
)

upsets <- upsets |> 
  mutate(
    predicted_prob=pred_probs
  )
```



```{r}
upsetsnew <- upsets |> filter(Season%in% c("2024-2025", "2025-2026"))

upsetsnew |>  filter(winloss == "1") |> 
arrange(predicted_prob) |> 
select(Team, Date, Opponent, TeamScore, OpponentScore, ToMargin, threepointdiscrepancy,FTmargin, predicted_prob)

upsetsnew <- upsetsnew |> mutate(Margin = TeamScore - OpponentScore)


upsetsnew <- upsetsnew |> 
  mutate(month=month(Date))
```
The model was mostly accurate in its predictions, predicting an over 50% chance of victory for the winning team in a significant majority of the upset games that existed, but it had its fair share of misses too. I decided to break down the games it missed by time of year to see if there were interesting trends.

```{r}
ggplot(upsetsnew, aes(x = factor(month), y = predicted_prob)) +
  geom_point(alpha = 0.6, size = 2) +
  labs(
    title = "Least predictable upsets often happen in November",
    x = "Month",
    y = "Win probability for eventual winning team"
  ) +
  geom_hline(yintercept=0.25) +
  theme_minimal()
```

The ones the model was most off on, AKA an under 25 percent probabliity of a victory for the eventual winning team, happened mostly in November. 


```{r}
shockers <- upsetsnew |> 
  filter(predicted_prob < 0.5)

combined <- data.frame(
  dataset = rep(c("upsetsnew", "shockers"), each = 2),
  category = rep(c("N", "Not N"), times = 2),
  percentage = c(
    sum(upsetsnew$HomeAway == "N", na.rm = TRUE) / nrow(upsetsnew) * 100,
    100 - (sum(upsetsnew$HomeAway == "N", na.rm = TRUE) / nrow(upsetsnew) * 100),
    sum(shockers$HomeAway == "N", na.rm = TRUE) / nrow(shockers) * 100,
    100 - (sum(shockers$HomeAway == "N", na.rm = TRUE) / nrow(shockers) * 100)
  )
)
```

November in college basketball is non-conference season so it largely makes sense that a majority of these wins would occur then, but it's also the home of many MTEs (Multiple Team Events) where schools meet in neutral locations often to play multiple games, like the Maui Invitational or the brand new Players Era in Las Vegas. 

```{r}

combined <- combined |>
  mutate(category = factor(category, levels = c("Not N", "N")))

ggplot(combined, aes(x = dataset, y = percentage, fill = category)) +
  geom_col() +  
  geom_text(aes(label = paste0(round(percentage, 1), "%")), 
            position = position_stack(vjust = 0.5),
            color = "white", size = 4, fontface = "bold") +
  scale_x_discrete(labels = c("upsetsnew" = "Over 25% Predicted Upsets", "shockers" = "Under 25% predicted upsets")) +
  labs(
    title = "Unpredictable upsets are more often on Neutral Courts",
    subtitle = "Early season MTEs lead to more hard-to-predict upsets",
    x = "Predicted vs. Non-predicted",
    y = "Neutral Court Percentage",
    fill = "Category"
  ) +
  scale_fill_manual(
    values = c("N" = "lightblue", "Not N" = "gray"),
    labels = c("N" = "Neutral Site", "Not N" = "True Home/Road")  
  )+
  theme_minimal()
```

I found that 9/21 games wherein the model was severely off occured on neutral courts good for almost 43% whereas in the games wherein the model predicted above 25% chance of a victory for the winning-team under 39% were on neutral courts. What does this say? Potentially that the early season just leads to a lot of hard-to-explain results, but also maybe the specific statistics I used as predictive factors are more relevant to games with a home crowd feeding off forcing the oppontent into turnovers or their team hitting big threes.


Pivoting slightly I wanted to explore which mid-major teams have had the most sustained success in pulling off wins against their more well-resourced foes. 
```{r}
upsets|>
  count(Team, sort = TRUE)
```

My results returned a lot of the usual suspects like San Diego State, Dayton, and Saint Mary's as well as a bunch of AAC teams. This is because many AAC programs have jumped ship for the Big-12, so previous conference wins against them are being classified as wins over a power program in the data. Eliminating them from the pool I explored some of the statistics from the other teams involved.

One I looked at over the data's time period was KenPom's adjusted Tempo stat to see if there's a trend among these succesful mid-major programs in regards to pace of play.

```{r}
tempo <- read_csv("Tempo Statistics - Sheet1.csv")

tempo <- tempo |> 
  rename(
    avg_tempo = `Avg Adjusted Tempo`,
    p5wins = `Power-Five Wins`
  )
```

```{r}


ggplot(tempo, aes(x = avg_tempo, y = p5wins)) +
  geom_point(alpha = 0.7) +
   geom_vline(xintercept = 67.61, linetype = "dashed") +   annotate(
    "text",
    x = 67.61,
    y = 28, 
    label = "National Avg Tempo (67.61)",
    vjust = -0.5,
    size = 3
  ) +
    scale_x_continuous(limits = c(60, 70)) +
  scale_y_continuous(limits = c(0, 30)) +
  geom_text_repel(
    aes(label = Team),
    size = 3,
    max.overlaps = 20
  ) +
  labs(
    x = "Average Adjusted Tempo (2015-Now)",
    y = "Power 5 Wins (2015-now)",
    title = "Succesful Mid-Majors play near or below average tempo",
    subtitle = "Data from teams with over 10 wins over power programs since 2014-15",
    caption = "Author: Max Schaeffer | Data: KenPom.com"
  ) +
  theme_minimal()
```

I found that mostly, these teams played below or at least close to the national average for pace of play, over the course of the 11.5 seasons of data I'm looking at. The three programs with the most wins against power opponents during this time period: Saint Mary's (CA), San Diego St. and Dayton were three of the four slowest paced teams of the group.

Conversely, many of the teams that played faster than the national average had future power head coaches come through the program. Nevada had Eric Musselman, Rhode Island had Danny Hurley, VCU had Will Wade and Mike Rhoades, San Francisco had Todd Golden. This didn't occur as often for the slower teams.


There is no catch-all solution for how to pull of an upset as a mid-major and teams have taken different routes to do it. Catching a team on a neutral court, winning the turnover battle, hitting a higher percentage of threes, getting to the line more often, and grinding a team down can all be predictive factors.

Sometimes, like Last November, a Colorado State team can beat TCU while turning the ball over three more times, shooting over 6% lower from beyond the arc, shooting 18 less free throws, and playing at a nearly equivalent pace. College basketball is weird. That's why I love it.